{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Cleaning - Remove rows with missing BMI values\n",
    "data = data.dropna(subset=['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Features and target\n",
    "X = data.drop(columns=['id', 'stroke'])\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Encode categorical variables\n",
    "categorical_features = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing (encoding) before resampling\n",
    "X_encoded = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Apply SMOTE to oversample the minority class to 3000 samples\n",
    "smote = SMOTE(sampling_strategy=1.0, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Apply undersampling only if the majority class has more than 3500 samples\n",
    "#majority_class_count = y_train_resampled.value_counts()[0]\n",
    "\n",
    "if majority_class_count > 3500:\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: 3500}, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = undersample.fit_resample(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled= scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ade14\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> (12.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,201\u001b[0m (12.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,201</span> (12.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,201\u001b[0m (12.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 9: Build the neural network model with Adamax optimizer and callbacks\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adamax optimizer and custom learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.0001), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.7291 - val_accuracy: 0.0046 - val_loss: 1.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6048 - loss: 0.7088 - val_accuracy: 0.0114 - val_loss: 0.9604 - learning_rate: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6145 - loss: 0.6711 - val_accuracy: 0.0167 - val_loss: 0.9238 - learning_rate: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6078 - loss: 0.6805 - val_accuracy: 0.0342 - val_loss: 0.8927 - learning_rate: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6103 - loss: 0.6597 - val_accuracy: 0.0509 - val_loss: 0.8671 - learning_rate: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6216 - loss: 0.6443 - val_accuracy: 0.0919 - val_loss: 0.8429 - learning_rate: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6271 - loss: 0.6265 - val_accuracy: 0.1193 - val_loss: 0.8227 - learning_rate: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6482 - loss: 0.6076 - val_accuracy: 0.1421 - val_loss: 0.8057 - learning_rate: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 0.6024 - val_accuracy: 0.2059 - val_loss: 0.7887 - learning_rate: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6455 - loss: 0.5856 - val_accuracy: 0.2713 - val_loss: 0.7751 - learning_rate: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6540 - loss: 0.5758 - val_accuracy: 0.3214 - val_loss: 0.7622 - learning_rate: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6676 - loss: 0.5673 - val_accuracy: 0.3898 - val_loss: 0.7489 - learning_rate: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6768 - loss: 0.5528 - val_accuracy: 0.4445 - val_loss: 0.7380 - learning_rate: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6812 - loss: 0.5538 - val_accuracy: 0.4992 - val_loss: 0.7262 - learning_rate: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6839 - loss: 0.5417 - val_accuracy: 0.5403 - val_loss: 0.7190 - learning_rate: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6943 - loss: 0.5367 - val_accuracy: 0.5790 - val_loss: 0.7082 - learning_rate: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7016 - loss: 0.5271 - val_accuracy: 0.6208 - val_loss: 0.6981 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6930 - loss: 0.5339 - val_accuracy: 0.6474 - val_loss: 0.6896 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6991 - loss: 0.5255 - val_accuracy: 0.6672 - val_loss: 0.6815 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7128 - loss: 0.5149 - val_accuracy: 0.6816 - val_loss: 0.6735 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7073 - loss: 0.5132 - val_accuracy: 0.6907 - val_loss: 0.6666 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.5029 - val_accuracy: 0.7105 - val_loss: 0.6595 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7181 - loss: 0.5020 - val_accuracy: 0.7234 - val_loss: 0.6523 - learning_rate: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7321 - loss: 0.4998 - val_accuracy: 0.7356 - val_loss: 0.6469 - learning_rate: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7271 - loss: 0.5049 - val_accuracy: 0.7386 - val_loss: 0.6436 - learning_rate: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7346 - loss: 0.4846 - val_accuracy: 0.7439 - val_loss: 0.6378 - learning_rate: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.4867 - val_accuracy: 0.7508 - val_loss: 0.6329 - learning_rate: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7331 - loss: 0.4930 - val_accuracy: 0.7538 - val_loss: 0.6298 - learning_rate: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7456 - loss: 0.4796 - val_accuracy: 0.7606 - val_loss: 0.6234 - learning_rate: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.4814 - val_accuracy: 0.7652 - val_loss: 0.6185 - learning_rate: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7542 - loss: 0.4803 - val_accuracy: 0.7698 - val_loss: 0.6140 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7537 - loss: 0.4767 - val_accuracy: 0.7736 - val_loss: 0.6110 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.4757 - val_accuracy: 0.7796 - val_loss: 0.6068 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7523 - loss: 0.4759 - val_accuracy: 0.7857 - val_loss: 0.6039 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7530 - loss: 0.4710 - val_accuracy: 0.7872 - val_loss: 0.6010 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7665 - loss: 0.4720 - val_accuracy: 0.7910 - val_loss: 0.5983 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7669 - loss: 0.4601 - val_accuracy: 0.7926 - val_loss: 0.5959 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.4592 - val_accuracy: 0.7941 - val_loss: 0.5922 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7779 - loss: 0.4556 - val_accuracy: 0.7971 - val_loss: 0.5889 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7838 - loss: 0.4544 - val_accuracy: 0.7994 - val_loss: 0.5861 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7639 - loss: 0.4626 - val_accuracy: 0.8047 - val_loss: 0.5832 - learning_rate: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7736 - loss: 0.4586 - val_accuracy: 0.8055 - val_loss: 0.5810 - learning_rate: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7727 - loss: 0.4488 - val_accuracy: 0.8085 - val_loss: 0.5792 - learning_rate: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7854 - loss: 0.4429 - val_accuracy: 0.8093 - val_loss: 0.5774 - learning_rate: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7756 - loss: 0.4532 - val_accuracy: 0.8116 - val_loss: 0.5750 - learning_rate: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7732 - loss: 0.4570 - val_accuracy: 0.8123 - val_loss: 0.5729 - learning_rate: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7797 - loss: 0.4502 - val_accuracy: 0.8146 - val_loss: 0.5713 - learning_rate: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7788 - loss: 0.4441 - val_accuracy: 0.8184 - val_loss: 0.5700 - learning_rate: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7761 - loss: 0.4485 - val_accuracy: 0.8229 - val_loss: 0.5677 - learning_rate: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7847 - loss: 0.4482 - val_accuracy: 0.8237 - val_loss: 0.5662 - learning_rate: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7781 - loss: 0.4397 - val_accuracy: 0.8245 - val_loss: 0.5646 - learning_rate: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7872 - loss: 0.4516 - val_accuracy: 0.8260 - val_loss: 0.5622 - learning_rate: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7816 - loss: 0.4366 - val_accuracy: 0.8267 - val_loss: 0.5614 - learning_rate: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7827 - loss: 0.4398 - val_accuracy: 0.8275 - val_loss: 0.5609 - learning_rate: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7804 - loss: 0.4440 - val_accuracy: 0.8267 - val_loss: 0.5602 - learning_rate: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7881 - loss: 0.4296 - val_accuracy: 0.8267 - val_loss: 0.5588 - learning_rate: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7837 - loss: 0.4402 - val_accuracy: 0.8267 - val_loss: 0.5562 - learning_rate: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7908 - loss: 0.4324 - val_accuracy: 0.8275 - val_loss: 0.5544 - learning_rate: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7861 - loss: 0.4393 - val_accuracy: 0.8275 - val_loss: 0.5533 - learning_rate: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7775 - loss: 0.4511 - val_accuracy: 0.8283 - val_loss: 0.5504 - learning_rate: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7823 - loss: 0.4465 - val_accuracy: 0.8313 - val_loss: 0.5489 - learning_rate: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7805 - loss: 0.4488 - val_accuracy: 0.8283 - val_loss: 0.5502 - learning_rate: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4299 - val_accuracy: 0.8305 - val_loss: 0.5497 - learning_rate: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7948 - loss: 0.4243 - val_accuracy: 0.8313 - val_loss: 0.5485 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7893 - loss: 0.4378 - val_accuracy: 0.8328 - val_loss: 0.5477 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4379 - val_accuracy: 0.8336 - val_loss: 0.5469 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.4273 - val_accuracy: 0.8351 - val_loss: 0.5441 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7964 - loss: 0.4344 - val_accuracy: 0.8351 - val_loss: 0.5431 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7873 - loss: 0.4289 - val_accuracy: 0.8351 - val_loss: 0.5415 - learning_rate: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7995 - loss: 0.4349 - val_accuracy: 0.8359 - val_loss: 0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4299 - val_accuracy: 0.8359 - val_loss: 0.5396 - learning_rate: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.4406 - val_accuracy: 0.8366 - val_loss: 0.5378 - learning_rate: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.4309 - val_accuracy: 0.8366 - val_loss: 0.5378 - learning_rate: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7986 - loss: 0.4281 - val_accuracy: 0.8374 - val_loss: 0.5352 - learning_rate: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7916 - loss: 0.4311 - val_accuracy: 0.8374 - val_loss: 0.5348 - learning_rate: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7958 - loss: 0.4271 - val_accuracy: 0.8374 - val_loss: 0.5349 - learning_rate: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7899 - loss: 0.4253 - val_accuracy: 0.8374 - val_loss: 0.5336 - learning_rate: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7897 - loss: 0.4408 - val_accuracy: 0.8374 - val_loss: 0.5335 - learning_rate: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8000 - loss: 0.4323 - val_accuracy: 0.8374 - val_loss: 0.5328 - learning_rate: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7976 - loss: 0.4291 - val_accuracy: 0.8381 - val_loss: 0.5322 - learning_rate: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7887 - loss: 0.4314 - val_accuracy: 0.8381 - val_loss: 0.5321 - learning_rate: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4231 - val_accuracy: 0.8381 - val_loss: 0.5314 - learning_rate: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8009 - loss: 0.4186 - val_accuracy: 0.8381 - val_loss: 0.5318 - learning_rate: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7953 - loss: 0.4277 - val_accuracy: 0.8381 - val_loss: 0.5314 - learning_rate: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.4317 - val_accuracy: 0.8381 - val_loss: 0.5321 - learning_rate: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4171 - val_accuracy: 0.8381 - val_loss: 0.5317 - learning_rate: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.4331 - val_accuracy: 0.8381 - val_loss: 0.5320 - learning_rate: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8001 - loss: 0.4326 - val_accuracy: 0.8374 - val_loss: 0.5318 - learning_rate: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8049 - loss: 0.4145 - val_accuracy: 0.8381 - val_loss: 0.5319 - learning_rate: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7989 - loss: 0.4232 - val_accuracy: 0.8374 - val_loss: 0.5300 - learning_rate: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4266 - val_accuracy: 0.8374 - val_loss: 0.5297 - learning_rate: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4098 - val_accuracy: 0.8389 - val_loss: 0.5285 - learning_rate: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 0.4155 - val_accuracy: 0.8389 - val_loss: 0.5283 - learning_rate: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 0.4103 - val_accuracy: 0.8381 - val_loss: 0.5289 - learning_rate: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.4169 - val_accuracy: 0.8397 - val_loss: 0.5276 - learning_rate: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4213 - val_accuracy: 0.8404 - val_loss: 0.5262 - learning_rate: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7986 - loss: 0.4223 - val_accuracy: 0.8397 - val_loss: 0.5259 - learning_rate: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.4103 - val_accuracy: 0.8397 - val_loss: 0.5256 - learning_rate: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.4234 - val_accuracy: 0.8397 - val_loss: 0.5257 - learning_rate: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8052 - loss: 0.4209 - val_accuracy: 0.8397 - val_loss: 0.5259 - learning_rate: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8141 - loss: 0.4127 - val_accuracy: 0.8404 - val_loss: 0.5240 - learning_rate: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8024 - loss: 0.4168 - val_accuracy: 0.8404 - val_loss: 0.5238 - learning_rate: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8117 - loss: 0.4094 - val_accuracy: 0.8397 - val_loss: 0.5238 - learning_rate: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.4076 - val_accuracy: 0.8397 - val_loss: 0.5235 - learning_rate: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8138 - loss: 0.4131 - val_accuracy: 0.8404 - val_loss: 0.5221 - learning_rate: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8111 - loss: 0.4114 - val_accuracy: 0.8404 - val_loss: 0.5218 - learning_rate: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8107 - loss: 0.4141 - val_accuracy: 0.8404 - val_loss: 0.5200 - learning_rate: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7962 - loss: 0.4239 - val_accuracy: 0.8404 - val_loss: 0.5201 - learning_rate: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8168 - loss: 0.3978 - val_accuracy: 0.8404 - val_loss: 0.5197 - learning_rate: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8085 - loss: 0.4169 - val_accuracy: 0.8412 - val_loss: 0.5172 - learning_rate: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8178 - loss: 0.4054 - val_accuracy: 0.8419 - val_loss: 0.5165 - learning_rate: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7960 - loss: 0.4193 - val_accuracy: 0.8412 - val_loss: 0.5164 - learning_rate: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8040 - loss: 0.4116 - val_accuracy: 0.8419 - val_loss: 0.5156 - learning_rate: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7937 - loss: 0.4262 - val_accuracy: 0.8419 - val_loss: 0.5147 - learning_rate: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8100 - loss: 0.4093 - val_accuracy: 0.8419 - val_loss: 0.5150 - learning_rate: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8135 - loss: 0.3977 - val_accuracy: 0.8419 - val_loss: 0.5141 - learning_rate: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4103 - val_accuracy: 0.8419 - val_loss: 0.5133 - learning_rate: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.4187 - val_accuracy: 0.8419 - val_loss: 0.5137 - learning_rate: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8085 - loss: 0.4097 - val_accuracy: 0.8412 - val_loss: 0.5134 - learning_rate: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8127 - loss: 0.4009 - val_accuracy: 0.8419 - val_loss: 0.5119 - learning_rate: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8080 - loss: 0.4007 - val_accuracy: 0.8419 - val_loss: 0.5119 - learning_rate: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.4065 - val_accuracy: 0.8419 - val_loss: 0.5117 - learning_rate: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8063 - loss: 0.3993 - val_accuracy: 0.8419 - val_loss: 0.5109 - learning_rate: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8071 - loss: 0.4110 - val_accuracy: 0.8419 - val_loss: 0.5102 - learning_rate: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8151 - loss: 0.4080 - val_accuracy: 0.8412 - val_loss: 0.5106 - learning_rate: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7903 - loss: 0.4308 - val_accuracy: 0.8419 - val_loss: 0.5089 - learning_rate: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4135 - val_accuracy: 0.8412 - val_loss: 0.5094 - learning_rate: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8160 - loss: 0.3993 - val_accuracy: 0.8412 - val_loss: 0.5085 - learning_rate: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8260 - loss: 0.3896 - val_accuracy: 0.8404 - val_loss: 0.5093 - learning_rate: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8138 - loss: 0.4109 - val_accuracy: 0.8404 - val_loss: 0.5084 - learning_rate: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8200 - loss: 0.4030 - val_accuracy: 0.8404 - val_loss: 0.5083 - learning_rate: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8000 - loss: 0.4135 - val_accuracy: 0.8404 - val_loss: 0.5068 - learning_rate: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8120 - loss: 0.4033 - val_accuracy: 0.8412 - val_loss: 0.5065 - learning_rate: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4203 - val_accuracy: 0.8412 - val_loss: 0.5059 - learning_rate: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8119 - loss: 0.4020 - val_accuracy: 0.8404 - val_loss: 0.5072 - learning_rate: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8152 - loss: 0.3921 - val_accuracy: 0.8404 - val_loss: 0.5067 - learning_rate: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8093 - loss: 0.4060 - val_accuracy: 0.8404 - val_loss: 0.5059 - learning_rate: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.4025 - val_accuracy: 0.8412 - val_loss: 0.5038 - learning_rate: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8145 - loss: 0.3988 - val_accuracy: 0.8412 - val_loss: 0.5030 - learning_rate: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.4041 - val_accuracy: 0.8412 - val_loss: 0.5020 - learning_rate: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8189 - loss: 0.3970 - val_accuracy: 0.8412 - val_loss: 0.5019 - learning_rate: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8123 - loss: 0.4024 - val_accuracy: 0.8419 - val_loss: 0.4999 - learning_rate: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8115 - loss: 0.4053 - val_accuracy: 0.8419 - val_loss: 0.4999 - learning_rate: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8208 - loss: 0.3842 - val_accuracy: 0.8419 - val_loss: 0.4989 - learning_rate: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8141 - loss: 0.3938 - val_accuracy: 0.8419 - val_loss: 0.4981 - learning_rate: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8114 - loss: 0.4059 - val_accuracy: 0.8419 - val_loss: 0.4975 - learning_rate: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8235 - loss: 0.3970 - val_accuracy: 0.8419 - val_loss: 0.4955 - learning_rate: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8201 - loss: 0.3941 - val_accuracy: 0.8412 - val_loss: 0.4958 - learning_rate: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8276 - loss: 0.3891 - val_accuracy: 0.8404 - val_loss: 0.4960 - learning_rate: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8196 - loss: 0.3969 - val_accuracy: 0.8412 - val_loss: 0.4936 - learning_rate: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.4025 - val_accuracy: 0.8412 - val_loss: 0.4938 - learning_rate: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.4102 - val_accuracy: 0.8412 - val_loss: 0.4935 - learning_rate: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8249 - loss: 0.3886 - val_accuracy: 0.8412 - val_loss: 0.4931 - learning_rate: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8210 - loss: 0.3947 - val_accuracy: 0.8404 - val_loss: 0.4942 - learning_rate: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8133 - loss: 0.3978 - val_accuracy: 0.8389 - val_loss: 0.4943 - learning_rate: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8252 - loss: 0.3890 - val_accuracy: 0.8397 - val_loss: 0.4932 - learning_rate: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8198 - loss: 0.3889 - val_accuracy: 0.8397 - val_loss: 0.4931 - learning_rate: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8174 - loss: 0.4100 - val_accuracy: 0.8397 - val_loss: 0.4933 - learning_rate: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8124 - loss: 0.3932 - val_accuracy: 0.8397 - val_loss: 0.4929 - learning_rate: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8135 - loss: 0.4078 - val_accuracy: 0.8397 - val_loss: 0.4943 - learning_rate: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8173 - loss: 0.3927 - val_accuracy: 0.8404 - val_loss: 0.4932 - learning_rate: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.3950 - val_accuracy: 0.8404 - val_loss: 0.4935 - learning_rate: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.3799 - val_accuracy: 0.8404 - val_loss: 0.4922 - learning_rate: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8142 - loss: 0.4029 - val_accuracy: 0.8404 - val_loss: 0.4912 - learning_rate: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8150 - loss: 0.4010 - val_accuracy: 0.8404 - val_loss: 0.4910 - learning_rate: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.3772 - val_accuracy: 0.8404 - val_loss: 0.4906 - learning_rate: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.4062 - val_accuracy: 0.8404 - val_loss: 0.4911 - learning_rate: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8164 - loss: 0.3932 - val_accuracy: 0.8404 - val_loss: 0.4904 - learning_rate: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - loss: 0.3948 - val_accuracy: 0.8419 - val_loss: 0.4892 - learning_rate: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8150 - loss: 0.3928 - val_accuracy: 0.8412 - val_loss: 0.4883 - learning_rate: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8182 - loss: 0.3951 - val_accuracy: 0.8442 - val_loss: 0.4865 - learning_rate: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8089 - loss: 0.4025 - val_accuracy: 0.8450 - val_loss: 0.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8190 - loss: 0.3882 - val_accuracy: 0.8442 - val_loss: 0.4849 - learning_rate: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8205 - loss: 0.3871 - val_accuracy: 0.8465 - val_loss: 0.4842 - learning_rate: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8215 - loss: 0.3825 - val_accuracy: 0.8442 - val_loss: 0.4853 - learning_rate: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8110 - loss: 0.3970 - val_accuracy: 0.8442 - val_loss: 0.4838 - learning_rate: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8238 - loss: 0.3849 - val_accuracy: 0.8450 - val_loss: 0.4832 - learning_rate: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.3854 - val_accuracy: 0.8442 - val_loss: 0.4838 - learning_rate: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8156 - loss: 0.3909 - val_accuracy: 0.8457 - val_loss: 0.4832 - learning_rate: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8239 - loss: 0.3925 - val_accuracy: 0.8457 - val_loss: 0.4831 - learning_rate: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8215 - loss: 0.3920 - val_accuracy: 0.8480 - val_loss: 0.4825 - learning_rate: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8205 - loss: 0.3885 - val_accuracy: 0.8473 - val_loss: 0.4822 - learning_rate: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8177 - loss: 0.3923 - val_accuracy: 0.8480 - val_loss: 0.4807 - learning_rate: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3915 - val_accuracy: 0.8480 - val_loss: 0.4793 - learning_rate: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8310 - loss: 0.3822 - val_accuracy: 0.8480 - val_loss: 0.4789 - learning_rate: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8246 - loss: 0.3794 - val_accuracy: 0.8480 - val_loss: 0.4785 - learning_rate: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8280 - loss: 0.3812 - val_accuracy: 0.8480 - val_loss: 0.4786 - learning_rate: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8271 - loss: 0.3825 - val_accuracy: 0.8488 - val_loss: 0.4782 - learning_rate: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - loss: 0.3898 - val_accuracy: 0.8488 - val_loss: 0.4775 - learning_rate: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.3757 - val_accuracy: 0.8495 - val_loss: 0.4771 - learning_rate: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8284 - loss: 0.3864 - val_accuracy: 0.8495 - val_loss: 0.4760 - learning_rate: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3797 - val_accuracy: 0.8495 - val_loss: 0.4744 - learning_rate: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8203 - loss: 0.3896 - val_accuracy: 0.8511 - val_loss: 0.4730 - learning_rate: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.3846 - val_accuracy: 0.8511 - val_loss: 0.4736 - learning_rate: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8181 - loss: 0.3905 - val_accuracy: 0.8495 - val_loss: 0.4740 - learning_rate: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3629 - val_accuracy: 0.8495 - val_loss: 0.4741 - learning_rate: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8251 - loss: 0.3780 - val_accuracy: 0.8503 - val_loss: 0.4737 - learning_rate: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8225 - loss: 0.3774 - val_accuracy: 0.8511 - val_loss: 0.4730 - learning_rate: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8214 - loss: 0.3849 - val_accuracy: 0.8518 - val_loss: 0.4722 - learning_rate: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.3871 - val_accuracy: 0.8518 - val_loss: 0.4719 - learning_rate: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8297 - loss: 0.3816 - val_accuracy: 0.8518 - val_loss: 0.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.3795 - val_accuracy: 0.8511 - val_loss: 0.4711 - learning_rate: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3852 - val_accuracy: 0.8518 - val_loss: 0.4698 - learning_rate: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.4011 - val_accuracy: 0.8511 - val_loss: 0.4698 - learning_rate: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8200 - loss: 0.3903 - val_accuracy: 0.8511 - val_loss: 0.4693 - learning_rate: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8117 - loss: 0.3954 - val_accuracy: 0.8511 - val_loss: 0.4696 - learning_rate: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8226 - loss: 0.3834 - val_accuracy: 0.8511 - val_loss: 0.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8151 - loss: 0.3879 - val_accuracy: 0.8503 - val_loss: 0.4716 - learning_rate: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8128 - loss: 0.3871 - val_accuracy: 0.8511 - val_loss: 0.4700 - learning_rate: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8184 - loss: 0.3935 - val_accuracy: 0.8518 - val_loss: 0.4695 - learning_rate: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3664 - val_accuracy: 0.8526 - val_loss: 0.4680 - learning_rate: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8247 - loss: 0.3819 - val_accuracy: 0.8533 - val_loss: 0.4677 - learning_rate: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.3789 - val_accuracy: 0.8541 - val_loss: 0.4669 - learning_rate: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.3843 - val_accuracy: 0.8541 - val_loss: 0.4660 - learning_rate: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - loss: 0.3893 - val_accuracy: 0.8549 - val_loss: 0.4649 - learning_rate: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8213 - loss: 0.3856 - val_accuracy: 0.8549 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3782 - val_accuracy: 0.8556 - val_loss: 0.4647 - learning_rate: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8219 - loss: 0.3917 - val_accuracy: 0.8556 - val_loss: 0.4630 - learning_rate: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.3737 - val_accuracy: 0.8556 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.3808 - val_accuracy: 0.8556 - val_loss: 0.4623 - learning_rate: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8260 - loss: 0.3772 - val_accuracy: 0.8556 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8327 - loss: 0.3750 - val_accuracy: 0.8556 - val_loss: 0.4617 - learning_rate: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.3709 - val_accuracy: 0.8556 - val_loss: 0.4609 - learning_rate: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.3681 - val_accuracy: 0.8556 - val_loss: 0.4602 - learning_rate: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8219 - loss: 0.3772 - val_accuracy: 0.8556 - val_loss: 0.4595 - learning_rate: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.3903 - val_accuracy: 0.8556 - val_loss: 0.4582 - learning_rate: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8356 - loss: 0.3740 - val_accuracy: 0.8571 - val_loss: 0.4566 - learning_rate: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8210 - loss: 0.3752 - val_accuracy: 0.8571 - val_loss: 0.4556 - learning_rate: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8270 - loss: 0.3730 - val_accuracy: 0.8564 - val_loss: 0.4560 - learning_rate: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.3677 - val_accuracy: 0.8564 - val_loss: 0.4569 - learning_rate: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8163 - loss: 0.3870 - val_accuracy: 0.8571 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8234 - loss: 0.3704 - val_accuracy: 0.8564 - val_loss: 0.4572 - learning_rate: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8180 - loss: 0.3837 - val_accuracy: 0.8556 - val_loss: 0.4578 - learning_rate: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8302 - loss: 0.3774 - val_accuracy: 0.8571 - val_loss: 0.4567 - learning_rate: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8389 - loss: 0.3580 - val_accuracy: 0.8571 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8257 - loss: 0.3808 - val_accuracy: 0.8564 - val_loss: 0.4558 - learning_rate: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8213 - loss: 0.3880 - val_accuracy: 0.8556 - val_loss: 0.4553 - learning_rate: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8248 - loss: 0.3761 - val_accuracy: 0.8571 - val_loss: 0.4542 - learning_rate: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8272 - loss: 0.3709 - val_accuracy: 0.8587 - val_loss: 0.4529 - learning_rate: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8252 - loss: 0.3728 - val_accuracy: 0.8579 - val_loss: 0.4532 - learning_rate: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.3744 - val_accuracy: 0.8579 - val_loss: 0.4528 - learning_rate: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.3691 - val_accuracy: 0.8571 - val_loss: 0.4536 - learning_rate: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8209 - loss: 0.3842 - val_accuracy: 0.8587 - val_loss: 0.4520 - learning_rate: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - loss: 0.3862 - val_accuracy: 0.8571 - val_loss: 0.4520 - learning_rate: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8245 - loss: 0.3769 - val_accuracy: 0.8571 - val_loss: 0.4518 - learning_rate: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3730 - val_accuracy: 0.8571 - val_loss: 0.4523 - learning_rate: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.3664 - val_accuracy: 0.8571 - val_loss: 0.4521 - learning_rate: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.3759 - val_accuracy: 0.8571 - val_loss: 0.4512 - learning_rate: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.3731 - val_accuracy: 0.8571 - val_loss: 0.4510 - learning_rate: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8228 - loss: 0.3729 - val_accuracy: 0.8571 - val_loss: 0.4500 - learning_rate: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8300 - loss: 0.3653 - val_accuracy: 0.8571 - val_loss: 0.4508 - learning_rate: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8262 - loss: 0.3704 - val_accuracy: 0.8571 - val_loss: 0.4502 - learning_rate: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.3644 - val_accuracy: 0.8571 - val_loss: 0.4497 - learning_rate: 1.0000e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.3719 - val_accuracy: 0.8571 - val_loss: 0.4490 - learning_rate: 1.0000e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.3678 - val_accuracy: 0.8579 - val_loss: 0.4478 - learning_rate: 1.0000e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8275 - loss: 0.3754 - val_accuracy: 0.8579 - val_loss: 0.4481 - learning_rate: 1.0000e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8280 - loss: 0.3808 - val_accuracy: 0.8579 - val_loss: 0.4482 - learning_rate: 1.0000e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3773 - val_accuracy: 0.8579 - val_loss: 0.4482 - learning_rate: 1.0000e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3839 - val_accuracy: 0.8579 - val_loss: 0.4480 - learning_rate: 1.0000e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 0.3811 - val_accuracy: 0.8594 - val_loss: 0.4465 - learning_rate: 1.0000e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.3658 - val_accuracy: 0.8594 - val_loss: 0.4456 - learning_rate: 1.0000e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.3658 - val_accuracy: 0.8594 - val_loss: 0.4462 - learning_rate: 1.0000e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3578 - val_accuracy: 0.8602 - val_loss: 0.4455 - learning_rate: 1.0000e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8246 - loss: 0.3715 - val_accuracy: 0.8602 - val_loss: 0.4455 - learning_rate: 1.0000e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8346 - loss: 0.3662 - val_accuracy: 0.8602 - val_loss: 0.4441 - learning_rate: 1.0000e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8326 - loss: 0.3614 - val_accuracy: 0.8602 - val_loss: 0.4433 - learning_rate: 1.0000e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8225 - loss: 0.3736 - val_accuracy: 0.8625 - val_loss: 0.4417 - learning_rate: 1.0000e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3665 - val_accuracy: 0.8617 - val_loss: 0.4430 - learning_rate: 1.0000e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.3673 - val_accuracy: 0.8609 - val_loss: 0.4432 - learning_rate: 1.0000e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.3729 - val_accuracy: 0.8617 - val_loss: 0.4427 - learning_rate: 1.0000e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.3710 - val_accuracy: 0.8594 - val_loss: 0.4440 - learning_rate: 1.0000e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.3724 - val_accuracy: 0.8602 - val_loss: 0.4435 - learning_rate: 1.0000e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8381 - loss: 0.3496 - val_accuracy: 0.8602 - val_loss: 0.4441 - learning_rate: 1.0000e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.3554 - val_accuracy: 0.8617 - val_loss: 0.4434 - learning_rate: 1.0000e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8193 - loss: 0.3782 - val_accuracy: 0.8640 - val_loss: 0.4417 - learning_rate: 1.0000e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.3704 - val_accuracy: 0.8640 - val_loss: 0.4416 - learning_rate: 1.0000e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3505 - val_accuracy: 0.8647 - val_loss: 0.4407 - learning_rate: 1.0000e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8289 - loss: 0.3725 - val_accuracy: 0.8647 - val_loss: 0.4412 - learning_rate: 1.0000e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3622 - val_accuracy: 0.8647 - val_loss: 0.4411 - learning_rate: 1.0000e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8301 - loss: 0.3788 - val_accuracy: 0.8647 - val_loss: 0.4400 - learning_rate: 1.0000e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.3534 - val_accuracy: 0.8647 - val_loss: 0.4399 - learning_rate: 1.0000e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8295 - loss: 0.3680 - val_accuracy: 0.8647 - val_loss: 0.4386 - learning_rate: 1.0000e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3599 - val_accuracy: 0.8655 - val_loss: 0.4377 - learning_rate: 1.0000e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.3561 - val_accuracy: 0.8647 - val_loss: 0.4376 - learning_rate: 1.0000e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.3542 - val_accuracy: 0.8647 - val_loss: 0.4381 - learning_rate: 1.0000e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8278 - loss: 0.3665 - val_accuracy: 0.8655 - val_loss: 0.4367 - learning_rate: 1.0000e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3536 - val_accuracy: 0.8655 - val_loss: 0.4363 - learning_rate: 1.0000e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8310 - loss: 0.3620 - val_accuracy: 0.8655 - val_loss: 0.4358 - learning_rate: 1.0000e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8212 - loss: 0.3743 - val_accuracy: 0.8655 - val_loss: 0.4349 - learning_rate: 1.0000e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8396 - loss: 0.3488 - val_accuracy: 0.8655 - val_loss: 0.4342 - learning_rate: 1.0000e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.3659 - val_accuracy: 0.8655 - val_loss: 0.4343 - learning_rate: 1.0000e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3519 - val_accuracy: 0.8655 - val_loss: 0.4336 - learning_rate: 1.0000e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3603 - val_accuracy: 0.8655 - val_loss: 0.4328 - learning_rate: 1.0000e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8324 - loss: 0.3586 - val_accuracy: 0.8655 - val_loss: 0.4330 - learning_rate: 1.0000e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8309 - loss: 0.3751 - val_accuracy: 0.8655 - val_loss: 0.4336 - learning_rate: 1.0000e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.3657 - val_accuracy: 0.8655 - val_loss: 0.4337 - learning_rate: 1.0000e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.3631 - val_accuracy: 0.8655 - val_loss: 0.4332 - learning_rate: 1.0000e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.3550 - val_accuracy: 0.8655 - val_loss: 0.4338 - learning_rate: 1.0000e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8307 - loss: 0.3651 - val_accuracy: 0.8655 - val_loss: 0.4338 - learning_rate: 1.0000e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.3614 - val_accuracy: 0.8663 - val_loss: 0.4334 - learning_rate: 1.0000e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3581 - val_accuracy: 0.8663 - val_loss: 0.4327 - learning_rate: 1.0000e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8256 - loss: 0.3704 - val_accuracy: 0.8670 - val_loss: 0.4309 - learning_rate: 1.0000e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8370 - loss: 0.3630 - val_accuracy: 0.8670 - val_loss: 0.4313 - learning_rate: 1.0000e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8332 - loss: 0.3622 - val_accuracy: 0.8678 - val_loss: 0.4305 - learning_rate: 1.0000e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3554 - val_accuracy: 0.8685 - val_loss: 0.4295 - learning_rate: 1.0000e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8268 - loss: 0.3574 - val_accuracy: 0.8685 - val_loss: 0.4292 - learning_rate: 1.0000e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8452 - loss: 0.3598 - val_accuracy: 0.8693 - val_loss: 0.4278 - learning_rate: 1.0000e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3528 - val_accuracy: 0.8693 - val_loss: 0.4273 - learning_rate: 1.0000e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 0.3593 - val_accuracy: 0.8701 - val_loss: 0.4267 - learning_rate: 1.0000e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8403 - loss: 0.3553 - val_accuracy: 0.8708 - val_loss: 0.4266 - learning_rate: 1.0000e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3585 - val_accuracy: 0.8708 - val_loss: 0.4271 - learning_rate: 1.0000e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.3556 - val_accuracy: 0.8708 - val_loss: 0.4260 - learning_rate: 1.0000e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8408 - loss: 0.3549 - val_accuracy: 0.8708 - val_loss: 0.4264 - learning_rate: 1.0000e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8454 - loss: 0.3538 - val_accuracy: 0.8708 - val_loss: 0.4269 - learning_rate: 1.0000e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.3723 - val_accuracy: 0.8708 - val_loss: 0.4261 - learning_rate: 1.0000e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.3579 - val_accuracy: 0.8708 - val_loss: 0.4252 - learning_rate: 1.0000e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8434 - loss: 0.3485 - val_accuracy: 0.8708 - val_loss: 0.4245 - learning_rate: 1.0000e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3566 - val_accuracy: 0.8708 - val_loss: 0.4242 - learning_rate: 1.0000e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.3512 - val_accuracy: 0.8708 - val_loss: 0.4223 - learning_rate: 1.0000e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8321 - loss: 0.3569 - val_accuracy: 0.8708 - val_loss: 0.4232 - learning_rate: 1.0000e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8412 - loss: 0.3490 - val_accuracy: 0.8708 - val_loss: 0.4236 - learning_rate: 1.0000e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.3647 - val_accuracy: 0.8716 - val_loss: 0.4230 - learning_rate: 1.0000e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8420 - loss: 0.3646 - val_accuracy: 0.8723 - val_loss: 0.4222 - learning_rate: 1.0000e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3524 - val_accuracy: 0.8723 - val_loss: 0.4217 - learning_rate: 1.0000e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8350 - loss: 0.3583 - val_accuracy: 0.8731 - val_loss: 0.4215 - learning_rate: 1.0000e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8433 - loss: 0.3580 - val_accuracy: 0.8739 - val_loss: 0.4207 - learning_rate: 1.0000e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.3450 - val_accuracy: 0.8754 - val_loss: 0.4202 - learning_rate: 1.0000e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3628 - val_accuracy: 0.8739 - val_loss: 0.4216 - learning_rate: 1.0000e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8404 - loss: 0.3523 - val_accuracy: 0.8746 - val_loss: 0.4206 - learning_rate: 1.0000e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3594 - val_accuracy: 0.8761 - val_loss: 0.4205 - learning_rate: 1.0000e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3399 - val_accuracy: 0.8761 - val_loss: 0.4202 - learning_rate: 1.0000e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.3549 - val_accuracy: 0.8761 - val_loss: 0.4196 - learning_rate: 1.0000e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3648 - val_accuracy: 0.8761 - val_loss: 0.4197 - learning_rate: 1.0000e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3441 - val_accuracy: 0.8769 - val_loss: 0.4180 - learning_rate: 1.0000e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8270 - loss: 0.3732 - val_accuracy: 0.8769 - val_loss: 0.4181 - learning_rate: 1.0000e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3605 - val_accuracy: 0.8769 - val_loss: 0.4178 - learning_rate: 1.0000e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8512 - loss: 0.3341 - val_accuracy: 0.8777 - val_loss: 0.4170 - learning_rate: 1.0000e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.3506 - val_accuracy: 0.8761 - val_loss: 0.4163 - learning_rate: 1.0000e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.3517 - val_accuracy: 0.8761 - val_loss: 0.4164 - learning_rate: 1.0000e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8426 - loss: 0.3539 - val_accuracy: 0.8761 - val_loss: 0.4172 - learning_rate: 1.0000e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.3469 - val_accuracy: 0.8761 - val_loss: 0.4176 - learning_rate: 1.0000e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8501 - loss: 0.3434 - val_accuracy: 0.8761 - val_loss: 0.4175 - learning_rate: 1.0000e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3584 - val_accuracy: 0.8761 - val_loss: 0.4166 - learning_rate: 1.0000e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8349 - loss: 0.3729 - val_accuracy: 0.8761 - val_loss: 0.4149 - learning_rate: 1.0000e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8337 - loss: 0.3634 - val_accuracy: 0.8769 - val_loss: 0.4143 - learning_rate: 1.0000e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8488 - loss: 0.3538 - val_accuracy: 0.8769 - val_loss: 0.4131 - learning_rate: 1.0000e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8338 - loss: 0.3560 - val_accuracy: 0.8777 - val_loss: 0.4119 - learning_rate: 1.0000e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8372 - loss: 0.3704 - val_accuracy: 0.8777 - val_loss: 0.4129 - learning_rate: 1.0000e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8485 - loss: 0.3504 - val_accuracy: 0.8777 - val_loss: 0.4128 - learning_rate: 1.0000e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8387 - loss: 0.3505 - val_accuracy: 0.8769 - val_loss: 0.4125 - learning_rate: 1.0000e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8388 - loss: 0.3527 - val_accuracy: 0.8777 - val_loss: 0.4126 - learning_rate: 1.0000e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3649 - val_accuracy: 0.8784 - val_loss: 0.4117 - learning_rate: 1.0000e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8406 - loss: 0.3448 - val_accuracy: 0.8769 - val_loss: 0.4119 - learning_rate: 1.0000e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8383 - loss: 0.3548 - val_accuracy: 0.8792 - val_loss: 0.4108 - learning_rate: 1.0000e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8546 - loss: 0.3402 - val_accuracy: 0.8769 - val_loss: 0.4108 - learning_rate: 1.0000e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 0.3475 - val_accuracy: 0.8769 - val_loss: 0.4112 - learning_rate: 1.0000e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.3478 - val_accuracy: 0.8777 - val_loss: 0.4115 - learning_rate: 1.0000e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8395 - loss: 0.3596 - val_accuracy: 0.8777 - val_loss: 0.4113 - learning_rate: 1.0000e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8463 - loss: 0.3526 - val_accuracy: 0.8784 - val_loss: 0.4105 - learning_rate: 1.0000e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8440 - loss: 0.3488 - val_accuracy: 0.8777 - val_loss: 0.4104 - learning_rate: 1.0000e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.3426 - val_accuracy: 0.8807 - val_loss: 0.4087 - learning_rate: 1.0000e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8513 - loss: 0.3317 - val_accuracy: 0.8784 - val_loss: 0.4099 - learning_rate: 1.0000e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8357 - loss: 0.3587 - val_accuracy: 0.8784 - val_loss: 0.4097 - learning_rate: 1.0000e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8511 - loss: 0.3448 - val_accuracy: 0.8784 - val_loss: 0.4087 - learning_rate: 1.0000e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.3491 - val_accuracy: 0.8784 - val_loss: 0.4086 - learning_rate: 1.0000e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 0.3452 - val_accuracy: 0.8784 - val_loss: 0.4087 - learning_rate: 1.0000e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.3694 - val_accuracy: 0.8784 - val_loss: 0.4076 - learning_rate: 1.0000e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8453 - loss: 0.3486 - val_accuracy: 0.8792 - val_loss: 0.4065 - learning_rate: 1.0000e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8452 - loss: 0.3478 - val_accuracy: 0.8799 - val_loss: 0.4060 - learning_rate: 1.0000e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8479 - loss: 0.3477 - val_accuracy: 0.8799 - val_loss: 0.4057 - learning_rate: 1.0000e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.3627 - val_accuracy: 0.8792 - val_loss: 0.4049 - learning_rate: 1.0000e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8499 - loss: 0.3558 - val_accuracy: 0.8799 - val_loss: 0.4033 - learning_rate: 1.0000e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.3442 - val_accuracy: 0.8799 - val_loss: 0.4040 - learning_rate: 1.0000e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8537 - loss: 0.3419 - val_accuracy: 0.8799 - val_loss: 0.4041 - learning_rate: 1.0000e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8490 - loss: 0.3419 - val_accuracy: 0.8815 - val_loss: 0.4029 - learning_rate: 1.0000e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8487 - loss: 0.3434 - val_accuracy: 0.8815 - val_loss: 0.4013 - learning_rate: 1.0000e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3513 - val_accuracy: 0.8822 - val_loss: 0.4020 - learning_rate: 1.0000e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.3426 - val_accuracy: 0.8837 - val_loss: 0.4016 - learning_rate: 1.0000e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8507 - loss: 0.3434 - val_accuracy: 0.8830 - val_loss: 0.4020 - learning_rate: 1.0000e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8483 - loss: 0.3399 - val_accuracy: 0.8822 - val_loss: 0.4013 - learning_rate: 1.0000e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8530 - loss: 0.3337 - val_accuracy: 0.8822 - val_loss: 0.4006 - learning_rate: 1.0000e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3369 - val_accuracy: 0.8822 - val_loss: 0.4008 - learning_rate: 1.0000e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8532 - loss: 0.3361 - val_accuracy: 0.8822 - val_loss: 0.4019 - learning_rate: 1.0000e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.3579 - val_accuracy: 0.8822 - val_loss: 0.4020 - learning_rate: 1.0000e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3398 - val_accuracy: 0.8830 - val_loss: 0.4005 - learning_rate: 1.0000e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8523 - loss: 0.3298 - val_accuracy: 0.8830 - val_loss: 0.3991 - learning_rate: 1.0000e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3523 - val_accuracy: 0.8837 - val_loss: 0.3987 - learning_rate: 1.0000e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8568 - loss: 0.3344 - val_accuracy: 0.8830 - val_loss: 0.3996 - learning_rate: 1.0000e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3256 - val_accuracy: 0.8830 - val_loss: 0.4002 - learning_rate: 1.0000e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.3393 - val_accuracy: 0.8830 - val_loss: 0.3999 - learning_rate: 1.0000e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3578 - val_accuracy: 0.8830 - val_loss: 0.3990 - learning_rate: 1.0000e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3467 - val_accuracy: 0.8830 - val_loss: 0.3984 - learning_rate: 1.0000e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8417 - loss: 0.3501 - val_accuracy: 0.8837 - val_loss: 0.3979 - learning_rate: 1.0000e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8410 - loss: 0.3519 - val_accuracy: 0.8830 - val_loss: 0.3974 - learning_rate: 1.0000e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 0.3361 - val_accuracy: 0.8830 - val_loss: 0.3993 - learning_rate: 1.0000e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3309 - val_accuracy: 0.8822 - val_loss: 0.3994 - learning_rate: 1.0000e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3358 - val_accuracy: 0.8822 - val_loss: 0.3983 - learning_rate: 1.0000e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.3529 - val_accuracy: 0.8822 - val_loss: 0.3982 - learning_rate: 1.0000e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.3471 - val_accuracy: 0.8822 - val_loss: 0.3978 - learning_rate: 1.0000e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.3374 - val_accuracy: 0.8822 - val_loss: 0.3979 - learning_rate: 1.0000e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3391 - val_accuracy: 0.8822 - val_loss: 0.3983 - learning_rate: 1.0000e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8463 - loss: 0.3407 - val_accuracy: 0.8815 - val_loss: 0.3973 - learning_rate: 1.0000e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 0.3442 - val_accuracy: 0.8822 - val_loss: 0.3970 - learning_rate: 1.0000e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3351 - val_accuracy: 0.8837 - val_loss: 0.3954 - learning_rate: 1.0000e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3447 - val_accuracy: 0.8837 - val_loss: 0.3942 - learning_rate: 1.0000e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3573 - val_accuracy: 0.8837 - val_loss: 0.3937 - learning_rate: 1.0000e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3374 - val_accuracy: 0.8830 - val_loss: 0.3935 - learning_rate: 1.0000e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8507 - loss: 0.3374 - val_accuracy: 0.8830 - val_loss: 0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.3485 - val_accuracy: 0.8830 - val_loss: 0.3941 - learning_rate: 1.0000e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8503 - loss: 0.3360 - val_accuracy: 0.8830 - val_loss: 0.3944 - learning_rate: 1.0000e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 0.3449 - val_accuracy: 0.8822 - val_loss: 0.3957 - learning_rate: 1.0000e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8447 - loss: 0.3465 - val_accuracy: 0.8830 - val_loss: 0.3937 - learning_rate: 1.0000e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 0.3419 - val_accuracy: 0.8822 - val_loss: 0.3934 - learning_rate: 1.0000e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3379 - val_accuracy: 0.8830 - val_loss: 0.3921 - learning_rate: 1.0000e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8527 - loss: 0.3459 - val_accuracy: 0.8830 - val_loss: 0.3919 - learning_rate: 1.0000e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8488 - loss: 0.3342 - val_accuracy: 0.8830 - val_loss: 0.3914 - learning_rate: 1.0000e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8569 - loss: 0.3332 - val_accuracy: 0.8837 - val_loss: 0.3911 - learning_rate: 1.0000e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8480 - loss: 0.3338 - val_accuracy: 0.8837 - val_loss: 0.3912 - learning_rate: 1.0000e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8505 - loss: 0.3374 - val_accuracy: 0.8837 - val_loss: 0.3910 - learning_rate: 1.0000e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.3308 - val_accuracy: 0.8837 - val_loss: 0.3915 - learning_rate: 1.0000e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8522 - loss: 0.3368 - val_accuracy: 0.8845 - val_loss: 0.3895 - learning_rate: 1.0000e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3314 - val_accuracy: 0.8845 - val_loss: 0.3890 - learning_rate: 1.0000e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8614 - loss: 0.3157 - val_accuracy: 0.8853 - val_loss: 0.3890 - learning_rate: 1.0000e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8483 - loss: 0.3312 - val_accuracy: 0.8853 - val_loss: 0.3887 - learning_rate: 1.0000e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3437 - val_accuracy: 0.8853 - val_loss: 0.3873 - learning_rate: 1.0000e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3360 - val_accuracy: 0.8860 - val_loss: 0.3864 - learning_rate: 1.0000e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8601 - loss: 0.3245 - val_accuracy: 0.8853 - val_loss: 0.3868 - learning_rate: 1.0000e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8493 - loss: 0.3363 - val_accuracy: 0.8860 - val_loss: 0.3860 - learning_rate: 1.0000e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8490 - loss: 0.3380 - val_accuracy: 0.8860 - val_loss: 0.3864 - learning_rate: 1.0000e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8562 - loss: 0.3249 - val_accuracy: 0.8860 - val_loss: 0.3855 - learning_rate: 1.0000e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.3306 - val_accuracy: 0.8860 - val_loss: 0.3852 - learning_rate: 1.0000e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8439 - loss: 0.3504 - val_accuracy: 0.8860 - val_loss: 0.3848 - learning_rate: 1.0000e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8528 - loss: 0.3350 - val_accuracy: 0.8860 - val_loss: 0.3845 - learning_rate: 1.0000e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8461 - loss: 0.3405 - val_accuracy: 0.8860 - val_loss: 0.3840 - learning_rate: 1.0000e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8529 - loss: 0.3308 - val_accuracy: 0.8860 - val_loss: 0.3844 - learning_rate: 1.0000e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 0.3409 - val_accuracy: 0.8860 - val_loss: 0.3842 - learning_rate: 1.0000e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8485 - loss: 0.3321 - val_accuracy: 0.8860 - val_loss: 0.3850 - learning_rate: 1.0000e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3219 - val_accuracy: 0.8860 - val_loss: 0.3846 - learning_rate: 1.0000e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.3340 - val_accuracy: 0.8853 - val_loss: 0.3836 - learning_rate: 1.0000e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3398 - val_accuracy: 0.8853 - val_loss: 0.3839 - learning_rate: 1.0000e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.3238 - val_accuracy: 0.8845 - val_loss: 0.3835 - learning_rate: 1.0000e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3331 - val_accuracy: 0.8860 - val_loss: 0.3814 - learning_rate: 1.0000e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.3355 - val_accuracy: 0.8860 - val_loss: 0.3809 - learning_rate: 1.0000e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3458 - val_accuracy: 0.8853 - val_loss: 0.3827 - learning_rate: 1.0000e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8526 - loss: 0.3286 - val_accuracy: 0.8853 - val_loss: 0.3817 - learning_rate: 1.0000e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3343 - val_accuracy: 0.8845 - val_loss: 0.3822 - learning_rate: 1.0000e-04\n",
      "Epoch 447/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8560 - loss: 0.3317 - val_accuracy: 0.8845 - val_loss: 0.3823 - learning_rate: 1.0000e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8585 - loss: 0.3216 - val_accuracy: 0.8845 - val_loss: 0.3822 - learning_rate: 1.0000e-04\n",
      "Epoch 449/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8474 - loss: 0.3379 - val_accuracy: 0.8853 - val_loss: 0.3799 - learning_rate: 1.0000e-04\n",
      "Epoch 450/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3299 - val_accuracy: 0.8868 - val_loss: 0.3784 - learning_rate: 1.0000e-04\n",
      "Epoch 451/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3341 - val_accuracy: 0.8860 - val_loss: 0.3789 - learning_rate: 1.0000e-04\n",
      "Epoch 452/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3524 - val_accuracy: 0.8868 - val_loss: 0.3780 - learning_rate: 1.0000e-04\n",
      "Epoch 453/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8538 - loss: 0.3316 - val_accuracy: 0.8868 - val_loss: 0.3786 - learning_rate: 1.0000e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3429 - val_accuracy: 0.8868 - val_loss: 0.3793 - learning_rate: 1.0000e-04\n",
      "Epoch 455/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3358 - val_accuracy: 0.8868 - val_loss: 0.3798 - learning_rate: 1.0000e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8638 - loss: 0.3202 - val_accuracy: 0.8868 - val_loss: 0.3786 - learning_rate: 1.0000e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8556 - loss: 0.3242 - val_accuracy: 0.8868 - val_loss: 0.3788 - learning_rate: 1.0000e-04\n",
      "Epoch 458/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3280 - val_accuracy: 0.8868 - val_loss: 0.3792 - learning_rate: 1.0000e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3403 - val_accuracy: 0.8868 - val_loss: 0.3778 - learning_rate: 1.0000e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3194 - val_accuracy: 0.8875 - val_loss: 0.3766 - learning_rate: 1.0000e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3378 - val_accuracy: 0.8875 - val_loss: 0.3765 - learning_rate: 1.0000e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8508 - loss: 0.3224 - val_accuracy: 0.8875 - val_loss: 0.3761 - learning_rate: 1.0000e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3434 - val_accuracy: 0.8883 - val_loss: 0.3752 - learning_rate: 1.0000e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3277 - val_accuracy: 0.8883 - val_loss: 0.3750 - learning_rate: 1.0000e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3228 - val_accuracy: 0.8883 - val_loss: 0.3760 - learning_rate: 1.0000e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8589 - loss: 0.3289 - val_accuracy: 0.8883 - val_loss: 0.3748 - learning_rate: 1.0000e-04\n",
      "Epoch 467/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8510 - loss: 0.3317 - val_accuracy: 0.8883 - val_loss: 0.3747 - learning_rate: 1.0000e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8579 - loss: 0.3249 - val_accuracy: 0.8883 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
      "Epoch 469/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3139 - val_accuracy: 0.8883 - val_loss: 0.3738 - learning_rate: 1.0000e-04\n",
      "Epoch 470/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8532 - loss: 0.3296 - val_accuracy: 0.8883 - val_loss: 0.3753 - learning_rate: 1.0000e-04\n",
      "Epoch 471/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8501 - loss: 0.3327 - val_accuracy: 0.8883 - val_loss: 0.3750 - learning_rate: 1.0000e-04\n",
      "Epoch 472/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8587 - loss: 0.3271 - val_accuracy: 0.8883 - val_loss: 0.3738 - learning_rate: 1.0000e-04\n",
      "Epoch 473/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 0.3306 - val_accuracy: 0.8883 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
      "Epoch 474/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.3270 - val_accuracy: 0.8883 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
      "Epoch 475/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3254 - val_accuracy: 0.8883 - val_loss: 0.3739 - learning_rate: 1.0000e-04\n",
      "Epoch 476/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8369 - loss: 0.3380 - val_accuracy: 0.8883 - val_loss: 0.3741 - learning_rate: 1.0000e-04\n",
      "Epoch 477/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8582 - loss: 0.3242 - val_accuracy: 0.8891 - val_loss: 0.3732 - learning_rate: 1.0000e-04\n",
      "Epoch 478/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3278 - val_accuracy: 0.8898 - val_loss: 0.3716 - learning_rate: 1.0000e-04\n",
      "Epoch 479/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8555 - loss: 0.3224 - val_accuracy: 0.8898 - val_loss: 0.3712 - learning_rate: 1.0000e-04\n",
      "Epoch 480/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 0.3330 - val_accuracy: 0.8906 - val_loss: 0.3699 - learning_rate: 1.0000e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8483 - loss: 0.3325 - val_accuracy: 0.8913 - val_loss: 0.3690 - learning_rate: 1.0000e-04\n",
      "Epoch 482/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3194 - val_accuracy: 0.8913 - val_loss: 0.3679 - learning_rate: 1.0000e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3302 - val_accuracy: 0.8913 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
      "Epoch 484/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3240 - val_accuracy: 0.8906 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
      "Epoch 485/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.3249 - val_accuracy: 0.8906 - val_loss: 0.3695 - learning_rate: 1.0000e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.3341 - val_accuracy: 0.8913 - val_loss: 0.3694 - learning_rate: 1.0000e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3244 - val_accuracy: 0.8913 - val_loss: 0.3686 - learning_rate: 1.0000e-04\n",
      "Epoch 488/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3301 - val_accuracy: 0.8906 - val_loss: 0.3683 - learning_rate: 1.0000e-04\n",
      "Epoch 489/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3251 - val_accuracy: 0.8898 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
      "Epoch 490/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3337 - val_accuracy: 0.8898 - val_loss: 0.3691 - learning_rate: 1.0000e-04\n",
      "Epoch 491/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3400 - val_accuracy: 0.8906 - val_loss: 0.3683 - learning_rate: 1.0000e-04\n",
      "Epoch 492/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.3252 - val_accuracy: 0.8906 - val_loss: 0.3671 - learning_rate: 1.0000e-04\n",
      "Epoch 493/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3182 - val_accuracy: 0.8906 - val_loss: 0.3673 - learning_rate: 1.0000e-04\n",
      "Epoch 494/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3097 - val_accuracy: 0.8906 - val_loss: 0.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 495/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8602 - loss: 0.3246 - val_accuracy: 0.8906 - val_loss: 0.3677 - learning_rate: 1.0000e-04\n",
      "Epoch 496/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3239 - val_accuracy: 0.8906 - val_loss: 0.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 497/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.3412 - val_accuracy: 0.8913 - val_loss: 0.3662 - learning_rate: 1.0000e-04\n",
      "Epoch 498/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3456 - val_accuracy: 0.8913 - val_loss: 0.3660 - learning_rate: 1.0000e-04\n",
      "Epoch 499/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 0.3157 - val_accuracy: 0.8921 - val_loss: 0.3663 - learning_rate: 1.0000e-04\n",
      "Epoch 500/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3179 - val_accuracy: 0.8906 - val_loss: 0.3670 - learning_rate: 1.0000e-04\n",
      "Epoch 501/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3115 - val_accuracy: 0.8913 - val_loss: 0.3664 - learning_rate: 1.0000e-04\n",
      "Epoch 502/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.3374 - val_accuracy: 0.8929 - val_loss: 0.3650 - learning_rate: 1.0000e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3145 - val_accuracy: 0.8898 - val_loss: 0.3660 - learning_rate: 1.0000e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3103 - val_accuracy: 0.8913 - val_loss: 0.3658 - learning_rate: 1.0000e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3308 - val_accuracy: 0.8921 - val_loss: 0.3662 - learning_rate: 1.0000e-04\n",
      "Epoch 506/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.3338 - val_accuracy: 0.8913 - val_loss: 0.3649 - learning_rate: 1.0000e-04\n",
      "Epoch 507/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.3291 - val_accuracy: 0.8913 - val_loss: 0.3640 - learning_rate: 1.0000e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3250 - val_accuracy: 0.8906 - val_loss: 0.3652 - learning_rate: 1.0000e-04\n",
      "Epoch 509/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.3070 - val_accuracy: 0.8906 - val_loss: 0.3659 - learning_rate: 1.0000e-04\n",
      "Epoch 510/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3217 - val_accuracy: 0.8891 - val_loss: 0.3665 - learning_rate: 1.0000e-04\n",
      "Epoch 511/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8466 - loss: 0.3422 - val_accuracy: 0.8906 - val_loss: 0.3650 - learning_rate: 1.0000e-04\n",
      "Epoch 512/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8678 - loss: 0.3227 - val_accuracy: 0.8906 - val_loss: 0.3639 - learning_rate: 1.0000e-04\n",
      "Epoch 513/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8486 - loss: 0.3292 - val_accuracy: 0.8913 - val_loss: 0.3628 - learning_rate: 1.0000e-04\n",
      "Epoch 514/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.3350 - val_accuracy: 0.8913 - val_loss: 0.3626 - learning_rate: 1.0000e-04\n",
      "Epoch 515/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.3273 - val_accuracy: 0.8913 - val_loss: 0.3614 - learning_rate: 1.0000e-04\n",
      "Epoch 516/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8556 - loss: 0.3309 - val_accuracy: 0.8913 - val_loss: 0.3611 - learning_rate: 1.0000e-04\n",
      "Epoch 517/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.3345 - val_accuracy: 0.8913 - val_loss: 0.3603 - learning_rate: 1.0000e-04\n",
      "Epoch 518/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3169 - val_accuracy: 0.8913 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
      "Epoch 519/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8418 - loss: 0.3331 - val_accuracy: 0.8906 - val_loss: 0.3604 - learning_rate: 1.0000e-04\n",
      "Epoch 520/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.2991 - val_accuracy: 0.8906 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
      "Epoch 521/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8546 - loss: 0.3393 - val_accuracy: 0.8906 - val_loss: 0.3590 - learning_rate: 1.0000e-04\n",
      "Epoch 522/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8516 - loss: 0.3245 - val_accuracy: 0.8898 - val_loss: 0.3591 - learning_rate: 1.0000e-04\n",
      "Epoch 523/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3112 - val_accuracy: 0.8913 - val_loss: 0.3578 - learning_rate: 1.0000e-04\n",
      "Epoch 524/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3189 - val_accuracy: 0.8906 - val_loss: 0.3590 - learning_rate: 1.0000e-04\n",
      "Epoch 525/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3159 - val_accuracy: 0.8913 - val_loss: 0.3577 - learning_rate: 1.0000e-04\n",
      "Epoch 526/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3323 - val_accuracy: 0.8913 - val_loss: 0.3577 - learning_rate: 1.0000e-04\n",
      "Epoch 527/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.3394 - val_accuracy: 0.8913 - val_loss: 0.3569 - learning_rate: 1.0000e-04\n",
      "Epoch 528/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.3104 - val_accuracy: 0.8913 - val_loss: 0.3562 - learning_rate: 1.0000e-04\n",
      "Epoch 529/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.3129 - val_accuracy: 0.8906 - val_loss: 0.3565 - learning_rate: 1.0000e-04\n",
      "Epoch 530/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.3161 - val_accuracy: 0.8906 - val_loss: 0.3564 - learning_rate: 1.0000e-04\n",
      "Epoch 531/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.3170 - val_accuracy: 0.8921 - val_loss: 0.3559 - learning_rate: 1.0000e-04\n",
      "Epoch 532/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.3149 - val_accuracy: 0.8929 - val_loss: 0.3551 - learning_rate: 1.0000e-04\n",
      "Epoch 533/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3047 - val_accuracy: 0.8913 - val_loss: 0.3563 - learning_rate: 1.0000e-04\n",
      "Epoch 534/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3129 - val_accuracy: 0.8913 - val_loss: 0.3550 - learning_rate: 1.0000e-04\n",
      "Epoch 535/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.3182 - val_accuracy: 0.8913 - val_loss: 0.3549 - learning_rate: 1.0000e-04\n",
      "Epoch 536/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3236 - val_accuracy: 0.8913 - val_loss: 0.3551 - learning_rate: 1.0000e-04\n",
      "Epoch 537/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 0.3295 - val_accuracy: 0.8913 - val_loss: 0.3549 - learning_rate: 1.0000e-04\n",
      "Epoch 538/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 0.3204 - val_accuracy: 0.8921 - val_loss: 0.3557 - learning_rate: 1.0000e-04\n",
      "Epoch 539/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 0.3103 - val_accuracy: 0.8913 - val_loss: 0.3574 - learning_rate: 1.0000e-04\n",
      "Epoch 540/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8587 - loss: 0.3177 - val_accuracy: 0.8913 - val_loss: 0.3566 - learning_rate: 1.0000e-04\n",
      "Epoch 541/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.3110 - val_accuracy: 0.8913 - val_loss: 0.3562 - learning_rate: 1.0000e-04\n",
      "Epoch 542/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.3279 - val_accuracy: 0.8913 - val_loss: 0.3556 - learning_rate: 1.0000e-04\n",
      "Epoch 543/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 0.3197 - val_accuracy: 0.8913 - val_loss: 0.3552 - learning_rate: 1.0000e-04\n",
      "Epoch 544/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.3156 - val_accuracy: 0.8921 - val_loss: 0.3544 - learning_rate: 1.0000e-04\n",
      "Epoch 545/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8616 - loss: 0.3186 - val_accuracy: 0.8913 - val_loss: 0.3542 - learning_rate: 1.0000e-04\n",
      "Epoch 546/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.3047 - val_accuracy: 0.8921 - val_loss: 0.3540 - learning_rate: 1.0000e-04\n",
      "Epoch 547/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.3253 - val_accuracy: 0.8929 - val_loss: 0.3542 - learning_rate: 1.0000e-04\n",
      "Epoch 548/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3248 - val_accuracy: 0.8944 - val_loss: 0.3515 - learning_rate: 1.0000e-04\n",
      "Epoch 549/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.3150 - val_accuracy: 0.8951 - val_loss: 0.3508 - learning_rate: 1.0000e-04\n",
      "Epoch 550/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3090 - val_accuracy: 0.8951 - val_loss: 0.3510 - learning_rate: 1.0000e-04\n",
      "Epoch 551/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3276 - val_accuracy: 0.8967 - val_loss: 0.3507 - learning_rate: 1.0000e-04\n",
      "Epoch 552/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.3158 - val_accuracy: 0.8944 - val_loss: 0.3526 - learning_rate: 1.0000e-04\n",
      "Epoch 553/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3132 - val_accuracy: 0.8951 - val_loss: 0.3519 - learning_rate: 1.0000e-04\n",
      "Epoch 554/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3270 - val_accuracy: 0.8951 - val_loss: 0.3515 - learning_rate: 1.0000e-04\n",
      "Epoch 555/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3183 - val_accuracy: 0.8951 - val_loss: 0.3526 - learning_rate: 1.0000e-04\n",
      "Epoch 556/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3150 - val_accuracy: 0.8944 - val_loss: 0.3526 - learning_rate: 1.0000e-04\n",
      "Epoch 557/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3252 - val_accuracy: 0.8944 - val_loss: 0.3523 - learning_rate: 1.0000e-04\n",
      "Epoch 558/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3088 - val_accuracy: 0.8959 - val_loss: 0.3506 - learning_rate: 1.0000e-04\n",
      "Epoch 559/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3408 - val_accuracy: 0.8967 - val_loss: 0.3493 - learning_rate: 1.0000e-04\n",
      "Epoch 560/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3089 - val_accuracy: 0.8959 - val_loss: 0.3495 - learning_rate: 1.0000e-04\n",
      "Epoch 561/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3051 - val_accuracy: 0.8951 - val_loss: 0.3506 - learning_rate: 1.0000e-04\n",
      "Epoch 562/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8674 - loss: 0.3159 - val_accuracy: 0.8951 - val_loss: 0.3500 - learning_rate: 1.0000e-04\n",
      "Epoch 563/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3103 - val_accuracy: 0.8974 - val_loss: 0.3489 - learning_rate: 1.0000e-04\n",
      "Epoch 564/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3133 - val_accuracy: 0.8967 - val_loss: 0.3492 - learning_rate: 1.0000e-04\n",
      "Epoch 565/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8603 - loss: 0.3034 - val_accuracy: 0.8959 - val_loss: 0.3489 - learning_rate: 1.0000e-04\n",
      "Epoch 566/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3118 - val_accuracy: 0.8951 - val_loss: 0.3488 - learning_rate: 1.0000e-04\n",
      "Epoch 567/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8645 - loss: 0.3111 - val_accuracy: 0.8936 - val_loss: 0.3505 - learning_rate: 1.0000e-04\n",
      "Epoch 568/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3138 - val_accuracy: 0.8959 - val_loss: 0.3490 - learning_rate: 1.0000e-04\n",
      "Epoch 569/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3239 - val_accuracy: 0.9005 - val_loss: 0.3480 - learning_rate: 1.0000e-04\n",
      "Epoch 570/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3204 - val_accuracy: 0.9012 - val_loss: 0.3477 - learning_rate: 1.0000e-04\n",
      "Epoch 571/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.3222 - val_accuracy: 0.9005 - val_loss: 0.3475 - learning_rate: 1.0000e-04\n",
      "Epoch 572/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3166 - val_accuracy: 0.9012 - val_loss: 0.3463 - learning_rate: 1.0000e-04\n",
      "Epoch 573/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3100 - val_accuracy: 0.9012 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
      "Epoch 574/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3070 - val_accuracy: 0.9012 - val_loss: 0.3448 - learning_rate: 1.0000e-04\n",
      "Epoch 575/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3186 - val_accuracy: 0.9012 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
      "Epoch 576/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8598 - loss: 0.3217 - val_accuracy: 0.9012 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
      "Epoch 577/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.3128 - val_accuracy: 0.9012 - val_loss: 0.3451 - learning_rate: 1.0000e-04\n",
      "Epoch 578/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3175 - val_accuracy: 0.9020 - val_loss: 0.3443 - learning_rate: 1.0000e-04\n",
      "Epoch 579/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.3106 - val_accuracy: 0.9005 - val_loss: 0.3455 - learning_rate: 1.0000e-04\n",
      "Epoch 580/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8545 - loss: 0.3139 - val_accuracy: 0.9020 - val_loss: 0.3447 - learning_rate: 1.0000e-04\n",
      "Epoch 581/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3137 - val_accuracy: 0.9005 - val_loss: 0.3438 - learning_rate: 1.0000e-04\n",
      "Epoch 582/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3099 - val_accuracy: 0.9005 - val_loss: 0.3440 - learning_rate: 1.0000e-04\n",
      "Epoch 583/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3050 - val_accuracy: 0.9005 - val_loss: 0.3455 - learning_rate: 1.0000e-04\n",
      "Epoch 584/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.3116 - val_accuracy: 0.9005 - val_loss: 0.3456 - learning_rate: 1.0000e-04\n",
      "Epoch 585/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3063 - val_accuracy: 0.9012 - val_loss: 0.3446 - learning_rate: 1.0000e-04\n",
      "Epoch 586/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3186 - val_accuracy: 0.9020 - val_loss: 0.3431 - learning_rate: 1.0000e-04\n",
      "Epoch 587/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3164 - val_accuracy: 0.9020 - val_loss: 0.3433 - learning_rate: 1.0000e-04\n",
      "Epoch 588/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3030 - val_accuracy: 0.9020 - val_loss: 0.3431 - learning_rate: 1.0000e-04\n",
      "Epoch 589/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.3155 - val_accuracy: 0.9027 - val_loss: 0.3427 - learning_rate: 1.0000e-04\n",
      "Epoch 590/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3110 - val_accuracy: 0.9043 - val_loss: 0.3417 - learning_rate: 1.0000e-04\n",
      "Epoch 591/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3164 - val_accuracy: 0.9020 - val_loss: 0.3435 - learning_rate: 1.0000e-04\n",
      "Epoch 592/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3094 - val_accuracy: 0.9035 - val_loss: 0.3422 - learning_rate: 1.0000e-04\n",
      "Epoch 593/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8693 - loss: 0.3022 - val_accuracy: 0.9035 - val_loss: 0.3425 - learning_rate: 1.0000e-04\n",
      "Epoch 594/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.3099 - val_accuracy: 0.9050 - val_loss: 0.3415 - learning_rate: 1.0000e-04\n",
      "Epoch 595/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8740 - loss: 0.3041 - val_accuracy: 0.9043 - val_loss: 0.3427 - learning_rate: 1.0000e-04\n",
      "Epoch 596/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8734 - loss: 0.3009 - val_accuracy: 0.9043 - val_loss: 0.3423 - learning_rate: 1.0000e-04\n",
      "Epoch 597/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3242 - val_accuracy: 0.9050 - val_loss: 0.3417 - learning_rate: 1.0000e-04\n",
      "Epoch 598/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.3011 - val_accuracy: 0.9065 - val_loss: 0.3412 - learning_rate: 1.0000e-04\n",
      "Epoch 599/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 0.3242 - val_accuracy: 0.9073 - val_loss: 0.3406 - learning_rate: 1.0000e-04\n",
      "Epoch 600/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8700 - loss: 0.3082 - val_accuracy: 0.9058 - val_loss: 0.3420 - learning_rate: 1.0000e-04\n",
      "Epoch 601/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8724 - loss: 0.2984 - val_accuracy: 0.9043 - val_loss: 0.3430 - learning_rate: 1.0000e-04\n",
      "Epoch 602/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.3119 - val_accuracy: 0.9043 - val_loss: 0.3431 - learning_rate: 1.0000e-04\n",
      "Epoch 603/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3059 - val_accuracy: 0.9035 - val_loss: 0.3422 - learning_rate: 1.0000e-04\n",
      "Epoch 604/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8666 - loss: 0.3124 - val_accuracy: 0.9035 - val_loss: 0.3419 - learning_rate: 1.0000e-04\n",
      "Epoch 605/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8608 - loss: 0.3026 - val_accuracy: 0.9043 - val_loss: 0.3408 - learning_rate: 1.0000e-04\n",
      "Epoch 606/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.3140 - val_accuracy: 0.9065 - val_loss: 0.3396 - learning_rate: 1.0000e-04\n",
      "Epoch 607/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3076 - val_accuracy: 0.9058 - val_loss: 0.3400 - learning_rate: 1.0000e-04\n",
      "Epoch 608/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3117 - val_accuracy: 0.9088 - val_loss: 0.3383 - learning_rate: 1.0000e-04\n",
      "Epoch 609/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8609 - loss: 0.3216 - val_accuracy: 0.9088 - val_loss: 0.3371 - learning_rate: 1.0000e-04\n",
      "Epoch 610/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8746 - loss: 0.2887 - val_accuracy: 0.9088 - val_loss: 0.3369 - learning_rate: 1.0000e-04\n",
      "Epoch 611/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8635 - loss: 0.3086 - val_accuracy: 0.9088 - val_loss: 0.3362 - learning_rate: 1.0000e-04\n",
      "Epoch 612/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8623 - loss: 0.3277 - val_accuracy: 0.9088 - val_loss: 0.3357 - learning_rate: 1.0000e-04\n",
      "Epoch 613/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.2988 - val_accuracy: 0.9088 - val_loss: 0.3353 - learning_rate: 1.0000e-04\n",
      "Epoch 614/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.3072 - val_accuracy: 0.9088 - val_loss: 0.3352 - learning_rate: 1.0000e-04\n",
      "Epoch 615/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3129 - val_accuracy: 0.9088 - val_loss: 0.3350 - learning_rate: 1.0000e-04\n",
      "Epoch 616/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.3036 - val_accuracy: 0.9088 - val_loss: 0.3352 - learning_rate: 1.0000e-04\n",
      "Epoch 617/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8693 - loss: 0.3006 - val_accuracy: 0.9088 - val_loss: 0.3363 - learning_rate: 1.0000e-04\n",
      "Epoch 618/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3122 - val_accuracy: 0.9088 - val_loss: 0.3361 - learning_rate: 1.0000e-04\n",
      "Epoch 619/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8696 - loss: 0.3094 - val_accuracy: 0.9088 - val_loss: 0.3352 - learning_rate: 1.0000e-04\n",
      "Epoch 620/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8686 - loss: 0.3042 - val_accuracy: 0.9096 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
      "Epoch 621/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.3010 - val_accuracy: 0.9096 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
      "Epoch 622/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.3195 - val_accuracy: 0.9096 - val_loss: 0.3325 - learning_rate: 1.0000e-04\n",
      "Epoch 623/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8644 - loss: 0.3059 - val_accuracy: 0.9088 - val_loss: 0.3335 - learning_rate: 1.0000e-04\n",
      "Epoch 624/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3043 - val_accuracy: 0.9088 - val_loss: 0.3339 - learning_rate: 1.0000e-04\n",
      "Epoch 625/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8718 - loss: 0.3019 - val_accuracy: 0.9065 - val_loss: 0.3346 - learning_rate: 1.0000e-04\n",
      "Epoch 626/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8727 - loss: 0.2945 - val_accuracy: 0.9065 - val_loss: 0.3347 - learning_rate: 1.0000e-04\n",
      "Epoch 627/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.3237 - val_accuracy: 0.9065 - val_loss: 0.3344 - learning_rate: 1.0000e-04\n",
      "Epoch 628/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3093 - val_accuracy: 0.9065 - val_loss: 0.3341 - learning_rate: 1.0000e-04\n",
      "Epoch 629/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.3127 - val_accuracy: 0.9058 - val_loss: 0.3348 - learning_rate: 1.0000e-04\n",
      "Epoch 630/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3176 - val_accuracy: 0.9058 - val_loss: 0.3347 - learning_rate: 1.0000e-04\n",
      "Epoch 631/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3162 - val_accuracy: 0.9073 - val_loss: 0.3332 - learning_rate: 1.0000e-04\n",
      "Epoch 632/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3035 - val_accuracy: 0.9088 - val_loss: 0.3320 - learning_rate: 1.0000e-04\n",
      "Epoch 633/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8682 - loss: 0.3015 - val_accuracy: 0.9081 - val_loss: 0.3319 - learning_rate: 1.0000e-04\n",
      "Epoch 634/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.2854 - val_accuracy: 0.9081 - val_loss: 0.3315 - learning_rate: 1.0000e-04\n",
      "Epoch 635/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.3199 - val_accuracy: 0.9065 - val_loss: 0.3333 - learning_rate: 1.0000e-04\n",
      "Epoch 636/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8632 - loss: 0.3088 - val_accuracy: 0.9081 - val_loss: 0.3319 - learning_rate: 1.0000e-04\n",
      "Epoch 637/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.3020 - val_accuracy: 0.9073 - val_loss: 0.3319 - learning_rate: 1.0000e-04\n",
      "Epoch 638/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.2977 - val_accuracy: 0.9073 - val_loss: 0.3315 - learning_rate: 1.0000e-04\n",
      "Epoch 639/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8621 - loss: 0.3139 - val_accuracy: 0.9073 - val_loss: 0.3314 - learning_rate: 1.0000e-04\n",
      "Epoch 640/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.2973 - val_accuracy: 0.9088 - val_loss: 0.3310 - learning_rate: 1.0000e-04\n",
      "Epoch 641/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3146 - val_accuracy: 0.9088 - val_loss: 0.3311 - learning_rate: 1.0000e-04\n",
      "Epoch 642/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8734 - loss: 0.2972 - val_accuracy: 0.9065 - val_loss: 0.3322 - learning_rate: 1.0000e-04\n",
      "Epoch 643/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8622 - loss: 0.3108 - val_accuracy: 0.9058 - val_loss: 0.3337 - learning_rate: 1.0000e-04\n",
      "Epoch 644/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8764 - loss: 0.2981 - val_accuracy: 0.9065 - val_loss: 0.3324 - learning_rate: 1.0000e-04\n",
      "Epoch 645/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8738 - loss: 0.2908 - val_accuracy: 0.9065 - val_loss: 0.3324 - learning_rate: 1.0000e-04\n",
      "Epoch 646/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.2959 - val_accuracy: 0.9073 - val_loss: 0.3319 - learning_rate: 1.0000e-04\n",
      "Epoch 647/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.3073 - val_accuracy: 0.9081 - val_loss: 0.3305 - learning_rate: 1.0000e-04\n",
      "Epoch 648/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3042 - val_accuracy: 0.9081 - val_loss: 0.3300 - learning_rate: 1.0000e-04\n",
      "Epoch 649/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8687 - loss: 0.3000 - val_accuracy: 0.9081 - val_loss: 0.3311 - learning_rate: 1.0000e-04\n",
      "Epoch 650/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.3026 - val_accuracy: 0.9073 - val_loss: 0.3319 - learning_rate: 1.0000e-04\n",
      "Epoch 651/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8717 - loss: 0.2975 - val_accuracy: 0.9081 - val_loss: 0.3316 - learning_rate: 1.0000e-04\n",
      "Epoch 652/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.3111 - val_accuracy: 0.9081 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
      "Epoch 653/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8758 - loss: 0.2954 - val_accuracy: 0.9081 - val_loss: 0.3295 - learning_rate: 1.0000e-04\n",
      "Epoch 654/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3044 - val_accuracy: 0.9081 - val_loss: 0.3289 - learning_rate: 1.0000e-04\n",
      "Epoch 655/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.2970 - val_accuracy: 0.9073 - val_loss: 0.3296 - learning_rate: 1.0000e-04\n",
      "Epoch 656/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.2949 - val_accuracy: 0.9073 - val_loss: 0.3290 - learning_rate: 1.0000e-04\n",
      "Epoch 657/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.2892 - val_accuracy: 0.9065 - val_loss: 0.3304 - learning_rate: 1.0000e-04\n",
      "Epoch 658/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8720 - loss: 0.2951 - val_accuracy: 0.9081 - val_loss: 0.3292 - learning_rate: 1.0000e-04\n",
      "Epoch 659/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8772 - loss: 0.2955 - val_accuracy: 0.9081 - val_loss: 0.3297 - learning_rate: 1.0000e-04\n",
      "Epoch 660/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3013 - val_accuracy: 0.9081 - val_loss: 0.3283 - learning_rate: 1.0000e-04\n",
      "Epoch 661/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8597 - loss: 0.3238 - val_accuracy: 0.9081 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
      "Epoch 662/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.2918 - val_accuracy: 0.9103 - val_loss: 0.3265 - learning_rate: 1.0000e-04\n",
      "Epoch 663/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8688 - loss: 0.2979 - val_accuracy: 0.9103 - val_loss: 0.3266 - learning_rate: 1.0000e-04\n",
      "Epoch 664/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3072 - val_accuracy: 0.9103 - val_loss: 0.3274 - learning_rate: 1.0000e-04\n",
      "Epoch 665/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8668 - loss: 0.3092 - val_accuracy: 0.9103 - val_loss: 0.3276 - learning_rate: 1.0000e-04\n",
      "Epoch 666/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8734 - loss: 0.2912 - val_accuracy: 0.9096 - val_loss: 0.3279 - learning_rate: 1.0000e-04\n",
      "Epoch 667/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3044 - val_accuracy: 0.9103 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
      "Epoch 668/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3107 - val_accuracy: 0.9103 - val_loss: 0.3270 - learning_rate: 1.0000e-04\n",
      "Epoch 669/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.3044 - val_accuracy: 0.9103 - val_loss: 0.3265 - learning_rate: 1.0000e-04\n",
      "Epoch 670/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8751 - loss: 0.2998 - val_accuracy: 0.9103 - val_loss: 0.3261 - learning_rate: 1.0000e-04\n",
      "Epoch 671/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3055 - val_accuracy: 0.9103 - val_loss: 0.3256 - learning_rate: 1.0000e-04\n",
      "Epoch 672/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.3070 - val_accuracy: 0.9103 - val_loss: 0.3253 - learning_rate: 1.0000e-04\n",
      "Epoch 673/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.3056 - val_accuracy: 0.9103 - val_loss: 0.3249 - learning_rate: 1.0000e-04\n",
      "Epoch 674/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.2960 - val_accuracy: 0.9111 - val_loss: 0.3257 - learning_rate: 1.0000e-04\n",
      "Epoch 675/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8709 - loss: 0.3026 - val_accuracy: 0.9126 - val_loss: 0.3240 - learning_rate: 1.0000e-04\n",
      "Epoch 676/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8665 - loss: 0.3061 - val_accuracy: 0.9126 - val_loss: 0.3238 - learning_rate: 1.0000e-04\n",
      "Epoch 677/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3073 - val_accuracy: 0.9103 - val_loss: 0.3253 - learning_rate: 1.0000e-04\n",
      "Epoch 678/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8742 - loss: 0.2965 - val_accuracy: 0.9111 - val_loss: 0.3232 - learning_rate: 1.0000e-04\n",
      "Epoch 679/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8625 - loss: 0.3051 - val_accuracy: 0.9111 - val_loss: 0.3232 - learning_rate: 1.0000e-04\n",
      "Epoch 680/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8764 - loss: 0.2950 - val_accuracy: 0.9119 - val_loss: 0.3225 - learning_rate: 1.0000e-04\n",
      "Epoch 681/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.2904 - val_accuracy: 0.9103 - val_loss: 0.3235 - learning_rate: 1.0000e-04\n",
      "Epoch 682/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8705 - loss: 0.3039 - val_accuracy: 0.9119 - val_loss: 0.3230 - learning_rate: 1.0000e-04\n",
      "Epoch 683/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.2886 - val_accuracy: 0.9111 - val_loss: 0.3226 - learning_rate: 1.0000e-04\n",
      "Epoch 684/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8733 - loss: 0.2916 - val_accuracy: 0.9111 - val_loss: 0.3226 - learning_rate: 1.0000e-04\n",
      "Epoch 685/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.2889 - val_accuracy: 0.9103 - val_loss: 0.3224 - learning_rate: 1.0000e-04\n",
      "Epoch 686/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8648 - loss: 0.3053 - val_accuracy: 0.9088 - val_loss: 0.3241 - learning_rate: 1.0000e-04\n",
      "Epoch 687/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8702 - loss: 0.2984 - val_accuracy: 0.9111 - val_loss: 0.3228 - learning_rate: 1.0000e-04\n",
      "Epoch 688/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.3006 - val_accuracy: 0.9119 - val_loss: 0.3220 - learning_rate: 1.0000e-04\n",
      "Epoch 689/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8753 - loss: 0.3006 - val_accuracy: 0.9119 - val_loss: 0.3212 - learning_rate: 1.0000e-04\n",
      "Epoch 690/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.2995 - val_accuracy: 0.9103 - val_loss: 0.3227 - learning_rate: 1.0000e-04\n",
      "Epoch 691/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8691 - loss: 0.3025 - val_accuracy: 0.9119 - val_loss: 0.3214 - learning_rate: 1.0000e-04\n",
      "Epoch 692/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3051 - val_accuracy: 0.9134 - val_loss: 0.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 693/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8703 - loss: 0.2994 - val_accuracy: 0.9134 - val_loss: 0.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 694/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.3104 - val_accuracy: 0.9134 - val_loss: 0.3211 - learning_rate: 1.0000e-04\n",
      "Epoch 695/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8781 - loss: 0.2884 - val_accuracy: 0.9134 - val_loss: 0.3206 - learning_rate: 1.0000e-04\n",
      "Epoch 696/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8700 - loss: 0.2967 - val_accuracy: 0.9134 - val_loss: 0.3200 - learning_rate: 1.0000e-04\n",
      "Epoch 697/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.2928 - val_accuracy: 0.9164 - val_loss: 0.3189 - learning_rate: 1.0000e-04\n",
      "Epoch 698/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.2996 - val_accuracy: 0.9164 - val_loss: 0.3193 - learning_rate: 1.0000e-04\n",
      "Epoch 699/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8722 - loss: 0.3027 - val_accuracy: 0.9164 - val_loss: 0.3185 - learning_rate: 1.0000e-04\n",
      "Epoch 700/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8780 - loss: 0.2922 - val_accuracy: 0.9164 - val_loss: 0.3187 - learning_rate: 1.0000e-04\n",
      "Epoch 701/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.2858 - val_accuracy: 0.9164 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 702/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3184 - val_accuracy: 0.9164 - val_loss: 0.3187 - learning_rate: 1.0000e-04\n",
      "Epoch 703/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.2794 - val_accuracy: 0.9187 - val_loss: 0.3166 - learning_rate: 1.0000e-04\n",
      "Epoch 704/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2719 - val_accuracy: 0.9179 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
      "Epoch 705/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.2928 - val_accuracy: 0.9179 - val_loss: 0.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 706/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.2925 - val_accuracy: 0.9157 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
      "Epoch 707/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.2871 - val_accuracy: 0.9157 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 708/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.2979 - val_accuracy: 0.9157 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 709/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.3009 - val_accuracy: 0.9141 - val_loss: 0.3183 - learning_rate: 1.0000e-04\n",
      "Epoch 710/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3012 - val_accuracy: 0.9141 - val_loss: 0.3197 - learning_rate: 1.0000e-04\n",
      "Epoch 711/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2877 - val_accuracy: 0.9157 - val_loss: 0.3181 - learning_rate: 1.0000e-04\n",
      "Epoch 712/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8749 - loss: 0.2984 - val_accuracy: 0.9141 - val_loss: 0.3198 - learning_rate: 1.0000e-04\n",
      "Epoch 713/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8662 - loss: 0.2926 - val_accuracy: 0.9157 - val_loss: 0.3173 - learning_rate: 1.0000e-04\n",
      "Epoch 714/1000\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.2872 - val_accuracy: 0.9164 - val_loss: 0.3165 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Step 10: Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, \n",
    "                    epochs=1000, batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=callbacks_list, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8581\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "# Step 12: Predictions and evaluation\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      1410\n",
      "           1       0.14      0.43      0.21        63\n",
      "\n",
      "    accuracy                           0.86      1473\n",
      "   macro avg       0.55      0.65      0.56      1473\n",
      "weighted avg       0.94      0.86      0.89      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to stroke_prediction_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Save the model to a file\n",
    "model.save('stroke_prediction_model.h5')\n",
    "print(\"Model saved to stroke_prediction_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
